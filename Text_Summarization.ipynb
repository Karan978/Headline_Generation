{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L6E9v4WtvyXU",
    "outputId": "81111db7-1ef8-488a-8a5b-e119548548e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary packages\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BTHYpzW3PeMB",
    "outputId": "8e3ac0af-c63d-4bdb-e018-4d837229d02d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GPU on Colab\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Pge-cIS21kiI",
    "outputId": "f2d65f95-72ce-4fc9-c740-2fd3e7eac396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Our data is on Google Drive. So, Google drive has to be mounted in Colab.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3v88P3PG1pCY"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('/content/drive/My Drive/news_summary_more.xlsx',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "_6yvkNg35Rpj",
    "outputId": "9dfc1f79-f7c8-4826-d8df-67565f9b9117"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-match winning streak</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customers save tax</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢Â‚Â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claims are not true: Sonam</td>\n",
       "      <td>Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             headlines                                                                                                                                                                                                     text\n",
       "0    upGrad learner switches to career in ML & Al with 90% salary hike  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...\n",
       "1         Delhi techie wins free food from Swiggy for one year on CRED  Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...\n",
       "2     New Zealand end Rohit Sharma-led India's 12-match winning streak  New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...\n",
       "3             Aegon life iTerm insurance plan helps customers save tax  With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢Â‚Â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, c...\n",
       "4  Have known Hirani for yrs, what if MeToo claims are not true: Sonam  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I..."
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xp_v4PvRLFlo",
    "outputId": "4584b435-7327-41af-f5e9-aa0e074fe6b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98400"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9sgX_gC8bZQJ"
   },
   "outputs": [],
   "source": [
    "#Creating empty dataframe to store  all the articles and corresponding headlines for first 95000 datapoints.\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "Sf8tBRYNb-0U",
    "outputId": "313ece61-67f7-4b13-b80a-ed32feb2662b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQ8NXJOGbTSW"
   },
   "outputs": [],
   "source": [
    "data=df.iloc[:95000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "elNFn1onciHv",
    "outputId": "9976ce93-074b-4fdb-9c5c-92a84404daee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-match winning streak</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customers save tax</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢Â‚Â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claims are not true: Sonam</td>\n",
       "      <td>Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             headlines                                                                                                                                                                                                     text\n",
       "0    upGrad learner switches to career in ML & Al with 90% salary hike  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...\n",
       "1         Delhi techie wins free food from Swiggy for one year on CRED  Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...\n",
       "2     New Zealand end Rohit Sharma-led India's 12-match winning streak  New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...\n",
       "3             Aegon life iTerm insurance plan helps customers save tax  With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢Â‚Â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, c...\n",
       "4  Have known Hirani for yrs, what if MeToo claims are not true: Sonam  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I..."
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uch4WodrdvTu",
    "outputId": "4f495b78-cd8d-4e0d-bb83-4d75e28929e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95000"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeVpnYdJFBDh"
   },
   "outputs": [],
   "source": [
    "#For some of the datapoints the headlines or article is missing or is corrupted. Hence in this step we will be dropping \n",
    "#such data points.\n",
    "a=[]\n",
    "b=[]\n",
    "for i in range(len(data['headlines'])):\n",
    "  if type(data['headlines'][i])!= str:\n",
    "    a.append(i)\n",
    "  if type(data['headlines'][i]) is datetime.datetime:\n",
    "    b.append(i)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XihIP7dGY6m1",
    "outputId": "0a858f86-c072-43b1-e22f-fc5a9962d49f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LS2ytrnmFbxy",
    "outputId": "ad90c0ff-c81f-4eef-e265-4bdbcb8f976f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21133, 33958, 40548, 42934, 74782, 91242]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LospgRjVV-Cf"
   },
   "outputs": [],
   "source": [
    "data.drop([data.index[21133],data.index[33958],data.index[40548],data.index[74782],data.index[91242],data.index[42934]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oruk9-luVBla",
    "outputId": "79b7c32a-6471-460e-e360-adefeba90f22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99994"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "seqe-jPAICiK",
    "outputId": "b9cbffda-3fb9-42aa-db82-455159474480"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSAlbAU46lpI"
   },
   "outputs": [],
   "source": [
    "contraction = { \n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I had\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"i'm\":\"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"i'd\": \"i had\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they had\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UTg-LVCE7I0Q"
   },
   "outputs": [],
   "source": [
    "# for contraction\n",
    "def contract(text):\n",
    "    description = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in contraction:\n",
    "            word = contraction[word]\n",
    "            description.append(word)\n",
    "        description.append(word)\n",
    "    return \" \".join(description)\n",
    "                \n",
    "# Here we are removing all non alpha numeric characters.\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = contract(text)\n",
    "    text = re.sub('[^A-Za-z0-9]', r' ',text)   \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iexEKL8fDJS3"
   },
   "outputs": [],
   "source": [
    "cleaned_text = data[\"text\"].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahpHaFUvEhLz"
   },
   "outputs": [],
   "source": [
    "cleaned_summary = data['headlines'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CE2K6davESiW"
   },
   "outputs": [],
   "source": [
    "data['text'] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KD5FFDs9Knu9"
   },
   "outputs": [],
   "source": [
    "data['headlines'] = cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "K3-QxoUSKjmk",
    "outputId": "ca35663a-f74c-4131-b0f1-cee0e1aec1dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml   al with 90  salary hike</td>\n",
       "      <td>saurav kant  an alumnus of upgrad and iiit b s pg program in machine learning and artificial intelligence  was a sr systems engineer at infosys with almost 5 years of work experience  the program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for one year on cred</td>\n",
       "      <td>kunal shah s credit card bill payment platform  cred  gave users a chance to win free food from swiggy for one year  pranav kaushik  a delhi techie  bagged this reward after spending 2000 cred coi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india s 12 match winning streak</td>\n",
       "      <td>new zealand defeated india by 8 wickets in the fourth odi at hamilton on thursday to win their first match of the five match odi series  india lost an international match under rohit sharma s capt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customers save tax</td>\n",
       "      <td>with aegon life iterm insurance plan  customers can enjoy tax benefits on your premiums paid and save up to       46 800  on taxes  the plan provides life cover up to the age of 100 years  also  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs  what if metoo claims are not true  sonam</td>\n",
       "      <td>speaking about the sexual harassment allegations against rajkumar hirani  sonam kapoor said   i ve known hirani for many years   what if it is it is not true  the   metoo  movement will get derail...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             headlines                                                                                                                                                                                                     text\n",
       "0    upgrad learner switches to career in ml   al with 90  salary hike  saurav kant  an alumnus of upgrad and iiit b s pg program in machine learning and artificial intelligence  was a sr systems engineer at infosys with almost 5 years of work experience  the program ...\n",
       "1         delhi techie wins free food from swiggy for one year on cred  kunal shah s credit card bill payment platform  cred  gave users a chance to win free food from swiggy for one year  pranav kaushik  a delhi techie  bagged this reward after spending 2000 cred coi...\n",
       "2     new zealand end rohit sharma led india s 12 match winning streak  new zealand defeated india by 8 wickets in the fourth odi at hamilton on thursday to win their first match of the five match odi series  india lost an international match under rohit sharma s capt...\n",
       "3             aegon life iterm insurance plan helps customers save tax  with aegon life iterm insurance plan  customers can enjoy tax benefits on your premiums paid and save up to       46 800  on taxes  the plan provides life cover up to the age of 100 years  also  c...\n",
       "4  have known hirani for yrs  what if metoo claims are not true  sonam  speaking about the sexual harassment allegations against rajkumar hirani  sonam kapoor said   i ve known hirani for many years   what if it is it is not true  the   metoo  movement will get derail..."
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHPBVZRnOhdU"
   },
   "outputs": [],
   "source": [
    "max_len_text = 0\n",
    "for i in data['text']:\n",
    "  l = len(i.split())\n",
    "  if l>max_len_text:\n",
    "    max_len_text = l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YYN_GbeM-O4c",
    "outputId": "529f82e4-64b2-4073-b6c4-dda412d33b93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXgH6FKR-P5t"
   },
   "outputs": [],
   "source": [
    "max_len_sum = 0\n",
    "for i in data['headlines']:\n",
    "  l = len(i.split())\n",
    "  if l>max_len_sum:\n",
    "    max_len_sum = l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1H0ztWTb-gdL",
    "outputId": "dad9d57a-5cdd-4063-e03f-94175d2a9b90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFxqvftU_lVW"
   },
   "outputs": [],
   "source": [
    "#Adding start and end token at beginning and end of each headline.\n",
    "data['headlines'] = data['headlines'].apply(lambda x:'S_ '+x+' _E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wi7KXl-c-h47"
   },
   "outputs": [],
   "source": [
    "#Tokenizing the articles and headlines.\n",
    "t1 = Tokenizer()\n",
    "X=data['text']\n",
    "t1.fit_on_texts(list(X))\n",
    "X = t1.texts_to_sequences(X)\n",
    "X = pad_sequences(X,maxlen=max_len_text,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2U5cSjsKDkuP"
   },
   "outputs": [],
   "source": [
    "#Adding 2 to the maximum length of headlines for beginning and ending token.\n",
    "max_len_sum = max_len_sum+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_YHhPP7DKwB"
   },
   "outputs": [],
   "source": [
    "t2 = Tokenizer()\n",
    "y=data['headlines']\n",
    "t2.fit_on_texts(list(y))\n",
    "y = t2.texts_to_sequences(y)\n",
    "y = pad_sequences(y,maxlen=max_len_sum,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "yWkBnTtoDpHR",
    "outputId": "167820c3-6059-409d-c5cd-ea4f6d0aa8ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25484,  6849,    26,  8010,     5,  9736,     6, 10908,  1529,\n",
       "            8,  9737,  1941,     4,  1885,  2288,     6,  1566,   780,\n",
       "           14,     3, 13550,  1888,  2489,    25,  1420,    17,   992,\n",
       "          100,    76,     5,   245,  1447,     1,  1941,     6,  9736,\n",
       "            8,  4917,  2764,   769,   487,  1047,    62,  5497,     2,\n",
       "            3,   244,  3861,    25,  2432,  2041,    17,  1175,  1642,\n",
       "         2458,  9736,     8,   331,   458,  2288,     9,  2349,   130,\n",
       "          119,  9491,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0],\n",
       "       [ 4883,   347,     8,  1513,  1225,   670,  1660,   567, 23799,\n",
       "          755,   188,     3,  2582,     2,   333,   498,   460,    23,\n",
       "         6510,    10,    64,    32, 15079,  8983,     3,    83, 21242,\n",
       "         4189,    39,  3120,    21,  2901,  2868, 23799,  4989,   188,\n",
       "          206,    64, 23799,  3974,   219,  3189,     5,   670,   674,\n",
       "           36,    88,    27,   181,     2,  5023,  9883,    23,  3912,\n",
       "           96, 33938, 16011, 22432, 12049,  2752,     6,   127,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mnj2crCvDqWC",
    "outputId": "6d498824-5d28-47bf-fb06-6d2f7ba3efcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 82)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenized articles.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LEjQ1S2oD3Bs",
    "outputId": "d0b7d58b-8bdc-4911-f1ff-3806d4761628"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95000, 24)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenized headlines.\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "EpLMCnN9D5e7",
    "outputId": "0c1f15d9-59e3-41b1-b035-d343fe47244f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  6, 74, 26, 33,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvUB32emIsmQ"
   },
   "outputs": [],
   "source": [
    "X_voc_size = (len(t1.word_index)+1)\n",
    "y_voc_size = (len(t2.word_index)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AezPx7LAR-wZ"
   },
   "outputs": [],
   "source": [
    "#We have defined our custom attention layer.I have used the General Score function for attention\n",
    "def Attention(enc_op,dec_op):\n",
    "  W = Dense(420)#This is a trainable weight matrix.\n",
    "  e = tf.matmul(dec_op,W(enc_op),transpose_b=True)\n",
    "  attention = tf.nn.softmax(e, axis=2)\n",
    "  context_vec = tf.matmul(attention,enc_op)\n",
    "\n",
    "  return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9bUkFQiEK4j"
   },
   "outputs": [],
   "source": [
    "\n",
    "def Encoder(en_input):\n",
    "  # en_input = np.resize(en_input,(None,82,32))\n",
    "  enc_emb = Embedding(X_voc_size,32,input_length=82,trainable=True)(en_input)\n",
    "  enc_lstm1 = Bidirectional(LSTM(210,return_sequences = True,return_state=True,batch_input_shape=(None,80,32)))\n",
    "  enc_op1, forward_h1, forward_c1, backward_h1, backward_c1 = enc_lstm1(enc_emb)\n",
    "\n",
    "  enc_lstm2 = Bidirectional(LSTM(210,return_sequences = True,return_state=True))\n",
    "  enc_op2, forward_h2, forward_c2, backward_h2, backward_c2 = enc_lstm2(enc_op1)\n",
    "\n",
    "  enc_h = Concatenate()([forward_h2, backward_h2])\n",
    "  enc_c = Concatenate()([forward_c2, backward_c2])\n",
    "\n",
    "\n",
    "  \n",
    "  return enc_op2,enc_h,enc_c\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJyqO0O6UnBK"
   },
   "outputs": [],
   "source": [
    "def Decoder(dec_ip,enc_op,state_h,state_c):\n",
    "  # dec_ip = np.resize(dec_ip,(None,23,32))\n",
    "  dec_emb = Embedding(y_voc_size,32,input_length=23,trainable=True)(dec_ip)\n",
    "\n",
    "  lstm = LSTM(420,return_sequences=True,return_state=True,batch_input_shape=(None,10,32))\n",
    "  dec_op,_,_ = lstm(dec_emb,initial_state=[state_h,state_c])\n",
    "\n",
    "  context_vec = Attention(enc_op,dec_op)\n",
    "\n",
    "  concat = Concatenate(axis=-1)([dec_op, context_vec])\n",
    "  return concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "poy9TOQabCAI"
   },
   "outputs": [],
   "source": [
    "def seq2seq():\n",
    "  en_ip = Input((82))\n",
    "  dec_ip = Input((23))\n",
    "\n",
    "  enc_op,state_h,state_c=Encoder(en_ip)\n",
    "\n",
    "  concat = Decoder(dec_ip,enc_op,state_h,state_c)\n",
    "\n",
    "  dense = Dense(y_voc_size,activation='softmax')\n",
    "  output = dense(concat)\n",
    "\n",
    "\n",
    "  model = Model([en_ip, dec_ip], output)\n",
    "  model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCxOSsRxL6e6"
   },
   "outputs": [],
   "source": [
    "model = seq2seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrDfPXQfgQak"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5xHxwpasOhvD"
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta = 0.23,mode='min',),\n",
    "             ModelCheckpoint('model_speed_pred.h5', monitor = 'val_loss',save_best_only = True, mode = 'min', verbose = 1,save_weights_only = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vcnL2I8RL9EN",
    "outputId": "a715935e-0066-48a1-d0b6-d7b79267588e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 3.6265\n",
      "Epoch 00001: val_loss improved from inf to 3.37401, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 134s 331ms/step - loss: 3.6265 - val_loss: 3.3740\n",
      "Epoch 2/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 3.2607\n",
      "Epoch 00002: val_loss improved from 3.37401 to 3.18783, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 328ms/step - loss: 3.2607 - val_loss: 3.1878\n",
      "Epoch 3/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 3.0688\n",
      "Epoch 00003: val_loss improved from 3.18783 to 3.06189, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 328ms/step - loss: 3.0688 - val_loss: 3.0619\n",
      "Epoch 4/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.9259\n",
      "Epoch 00004: val_loss improved from 3.06189 to 2.93272, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 328ms/step - loss: 2.9259 - val_loss: 2.9327\n",
      "Epoch 5/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.7938\n",
      "Epoch 00005: val_loss improved from 2.93272 to 2.84595, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.7938 - val_loss: 2.8459\n",
      "Epoch 6/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.6781\n",
      "Epoch 00006: val_loss improved from 2.84595 to 2.76771, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.6781 - val_loss: 2.7677\n",
      "Epoch 7/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.5820\n",
      "Epoch 00007: val_loss improved from 2.76771 to 2.70998, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.5820 - val_loss: 2.7100\n",
      "Epoch 8/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.4985\n",
      "Epoch 00008: val_loss improved from 2.70998 to 2.66214, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.4985 - val_loss: 2.6621\n",
      "Epoch 9/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.4222\n",
      "Epoch 00009: val_loss improved from 2.66214 to 2.63929, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.4222 - val_loss: 2.6393\n",
      "Epoch 10/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.3555\n",
      "Epoch 00010: val_loss improved from 2.63929 to 2.61247, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 330ms/step - loss: 2.3555 - val_loss: 2.6125\n",
      "Epoch 11/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.2904\n",
      "Epoch 00011: val_loss improved from 2.61247 to 2.58450, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.2904 - val_loss: 2.5845\n",
      "Epoch 12/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.2346\n",
      "Epoch 00012: val_loss improved from 2.58450 to 2.56271, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.2346 - val_loss: 2.5627\n",
      "Epoch 13/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.1790\n",
      "Epoch 00013: val_loss improved from 2.56271 to 2.55704, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.1790 - val_loss: 2.5570\n",
      "Epoch 14/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.1256\n",
      "Epoch 00014: val_loss improved from 2.55704 to 2.54826, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.1256 - val_loss: 2.5483\n",
      "Epoch 15/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.0761\n",
      "Epoch 00015: val_loss improved from 2.54826 to 2.54515, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.0761 - val_loss: 2.5451\n",
      "Epoch 16/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 2.0293\n",
      "Epoch 00016: val_loss improved from 2.54515 to 2.54168, saving model to model_speed_pred.h5\n",
      "404/404 [==============================] - 133s 329ms/step - loss: 2.0293 - val_loss: 2.5417\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f402278dd30>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,callbacks=callbacks,batch_size=212, validation_data=([X_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "8AMMNyuOakoy",
    "outputId": "5aa30d2e-1d5d-41af-9e4d-3674d9792ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 81)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 81, 32)       1107072     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 81, 420), (N 408240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 81, 420), (N 1060080     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 22, 32)       516864      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 420)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 420)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 22, 420), (N 761040      embedding_1[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 81, 420)      176820      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2 (Tens [(None, 22, 81)]     0           lstm_2[0][0]                     \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, 22, 81)]     0           tf_op_layer_BatchMatMulV2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_1 (Te [(None, 22, 420)]    0           tf_op_layer_Softmax[0][0]        \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 22, 840)      0           lstm_2[0][0]                     \n",
      "                                                                 tf_op_layer_BatchMatMulV2_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 22, 16152)    13583832    concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 17,613,948\n",
      "Trainable params: 17,613,948\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bwsqpIAwa5jn",
    "outputId": "8e97cf9c-0741-4770-89c5-592050a125df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16152"
      ]
     },
     "execution_count": 147,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_voc_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6KnEjm1pXoxA"
   },
   "outputs": [],
   "source": [
    "def inference():\n",
    "  i = np.random.randint(16000,98420)\n",
    "  en_ip1 = df['text'][i]\n",
    "  en_ip = t1.texts_to_sequences([en_ip1])\n",
    "  en_ip = np.array(en_ip)\n",
    "\n",
    "  dec_ip =  np.array([[t2.word_index['s']]])\n",
    "  op = model.predict([en_ip,dec_ip],verbose=0)\n",
    "  dec_ip1=[]\n",
    "  output=[]\n",
    "\n",
    "  while True:\n",
    "#     op = model.predict([en_ip,dec_ip],verbose=0)\n",
    "    dec_ip = tf.expand_dims(tf.argmax(op,axis=2),0)\n",
    "    dec_ip1.append(dec_ip)\n",
    "    op = model.predict([en_ip,dec_ip1],verbose=0)\n",
    "    # a = tf.argmax(op,axis=2)\n",
    "    # a = int(a)\n",
    "    # print(a)\n",
    "    # dec_ip = np.array(dec_ip)\n",
    "    output.append(t2.index_word[dec_ip.numpy()[0][0][0]])\n",
    "    \n",
    "    if output[-1] == 'e' or len(output) >= 23:\n",
    "      break\n",
    " \n",
    "  print(en_ip1)\n",
    "  print('Actual', df['headlines'][i])\n",
    "  print('Predicted',' '.join(output))\n",
    "  \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "eaA_Ke2rQjQn",
    "outputId": "332ada87-3c1f-4680-c836-e2e802864b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 82) for input Tensor(\"input_1:0\", shape=(None, 82), dtype=float32), but it was called on an input with incompatible shape (None, 61).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 23) for input Tensor(\"input_2:0\", shape=(None, 23), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 82) for input Tensor(\"input_1:0\", shape=(None, 82), dtype=float32), but it was called on an input with incompatible shape (None, 61).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 23) for input Tensor(\"input_2:0\", shape=(None, 23), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
      "tripura governor tathagata roy on tuesday tweeted   how one wishes gandhiji had anointed sardar vallabhbhai as the first prime minister of india  there would have been no kashmir problem   praising patel on his 142nd birth anniversary  roy said the  mahapurush  had welded india into a single country  he also flagged off the run for unity marathon at agartala s vivekananda maidan \n",
      "Actual S_ had gandhi made patel pm  j k would not would not be issue  tripura guv _E\n",
      "Predicted may not not not not not not not not not not not not not not not not not not not not not not\n"
     ]
    }
   ],
   "source": [
    "inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDcsh8aYSp5t"
   },
   "outputs": [],
   "source": [
    "  i = np.random.randint(16000,98420)\n",
    "  en_ip = df['text'][i]\n",
    "  en_ip = t1.texts_to_sequences(en_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "asbylaKmUCJM",
    "outputId": "6e0d4963-438f-4192-997d-0adfe3fac7f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(en_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v2mM3gXJV9Ru",
    "outputId": "81c40742-6f95-407b-8667-fe523daa8c65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362,)"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ip=np.array(en_ip)\n",
    "en_ip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Qq4o9abUEEM"
   },
   "outputs": [],
   "source": [
    "dec_ip =  np.array([[t2.word_index['s']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "55PIbjURVSK3",
    "outputId": "54d7b4b9-3eec-4408-ef85-97e84c637b62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jfVHB_wVVTLd",
    "outputId": "8b60da53-171b-4231-ea9a-fbcf1446b347"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dec_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "P8Bqj1z_VWja",
    "outputId": "70b6d9e8-ba66-4a70-e063-cc24e66265bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 82) for input Tensor(\"input_1:0\", shape=(None, 82), dtype=float32), but it was called on an input with incompatible shape (None, 61).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 23) for input Tensor(\"input_2:0\", shape=(None, 23), dtype=float32), but it was called on an input with incompatible shape (None, 14).\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(1,15000)\n",
    "en_ip1 = df['text'][i]\n",
    "en_ip = t1.texts_to_sequences([en_ip1])\n",
    "en_ip = np.array(en_ip)\n",
    "\n",
    "dec_ip1= df['headlines'][i]\n",
    "dec_ip = t1.texts_to_sequences([dec_ip1])\n",
    "dec_ip = np.array(dec_ip)\n",
    "dec_ip = dec_ip.reshape(1,dec_ip.shape[1], 1)\n",
    "\n",
    "pred = model.predict([en_ip,dec_ip])\n",
    "pred = tf.argmax(pred,axis=-1)\n",
    "\n",
    "# print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NcUgBZA5gHMs",
    "outputId": "8971c41c-c380-4d1d-c374-7dff8b02fabb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 14), dtype=int64, numpy=\n",
       "array([[  11,    7, 2556,   80,    7,    7, 2199, 2199, 1700, 2273,    2,\n",
       "           2,    2,    2]])>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "1gj2HF7IPWnY",
    "outputId": "0600dc33-bf31-42d4-e9de-f220ba67df54"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'actress swara bhasker has said a person s  sense of sanctity  does not lie in the body   shame is nothing  there is an integrity to our soul  even if our bodies are violated nobody can take our integrity from us   she added  swara further said   my learning for every girl out there is  do not subscribe to this notion of shame  '"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ip1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3uNSR6DEPahH",
    "outputId": "6cfedfbd-b819-4b63-daea-7a7e7124b69a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'S_ your sense of sanctity does not lie in your body  swara bhasker _E'"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_ip1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Text_Summarization",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
